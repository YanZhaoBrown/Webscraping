

## Project

This project will be a multiweek project that is due on Wednesday, November 28, 2018 at 9am. This project will consist of the following:

1. Data Scraping
2. Text mining 
3. Graphics
4. Reproducible research

More details follow below:


### Day 1: Data Scraping (November 7, 2018)

Find a topic that everyone in your group is interested in. Then try to find data which you can scrape with that. For example, you can scrape twitter data, election data, in the [example code](https://github.com/Sullivanstatistics/Dunkin_Scrape) I scrape the locations of Dunkin Donuts. It will take much of the first class to scrpae this data. 



### Day 2: Text Mining (November 14, 2018)

In this class you will spend more time scraping the data and then analyzing the text results. In my example, I did not analyze the text but just graphed and counted some simple things. You will need to use text mining/regular expressions to analyze the data though. You may wish to look for words or phrases, sentiments of statements, In the Dunkin data, I could have scraped the hours of operations or if they had wifi hotspots. 

### Graphics

Compile you results and create some useful graphs for this in a markdown document. The markdown should compile a report. 


### Reproducible Research

Follow the layout of the dunkin donuts scrape. 

- Each R code file serves a purpose, e.g. 1 file downloads the data, one file analyzes the data, the markdown file compiles a report and the make file allows everything to run.

Essentially this allows for you work to be updated over time by running one R file and it generates a new html file. With this set up, I could go ahead and have my document updated every second, hour, day or week. 



## Some ideas for data:

- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)
- [indeed](https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b)
- [Further examples](https://towardsdatascience.com/learn-to-create-your-own-datasets-web-scraping-in-r-f934a31748a5)


## Tips

- Clone this github repository
- Then open the R-Project not just the file
- When you make changes Follow these steps:
    - Add files changed
    - Commit Changes
    - Pull 
    - Push
    
    