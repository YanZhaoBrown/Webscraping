# Part 3 Text Mining 

Finally, we know that there is more to colleges than just numbers. We used text mining techniques and sentiment analysis on student reviews to create our own ranking of the schools.
```{r, echo = FALSE}
library(stringr)
library(rvest)
library(xml2)
library(dplyr)
library(RColorBrewer)

library(ggplot2)
library(wordcloud)
library(tidytext)

```
```{r, echo = FALSE}
# Run second
# This function gets the names of the schools from the first a pages and 
# puts them in the URL format
get_names=function(a){
  names=vector(length=0,mode="character")
  for(i in 1:a){
    url=str_c("https://www.niche.com/colleges/search/best-colleges/?page=",i)
     webpages <- read_html(url)
     name_data <- html_text(html_nodes(webpages, ".search-result__title" ))  
     name_data <- as.vector(name_data)
     names=c(names, name_data)
  }
  names=str_replace_all(names," ","-")
  names=str_replace_all(names, "&", "-and-")
  names[11] <- "Washington-University-in-St-Louis"
  return(names)
}

get_names(4)
```
```{r, echo = FALSE}
# Run Third
# This function simply gives the real names of the schools
get_real_names=function(a){
  names=vector(length=0,mode="character")
  for(i in 1:a){
    url=str_c("https://www.niche.com/colleges/search/best-colleges/?page=",i)
     webpages <- read_html(url)
     name_data <- html_text(html_nodes(webpages, ".search-result__title" ))  
     name_data <- as.vector(name_data)
     names=c(names, name_data)
  }
  return(names)
}
```

```{r, echo = FALSE}
#write a function to webscrape 20 reviews of each colleges and save them as reivew 
get_review <- function(schools){
  review=vector(length=0,mode="character")
  for(i in 1:length(schools)){
    url1 <-"https://www.niche.com/colleges"
    url2 <- str_c(url1,"/",schools[i],"/")
    url_review <- str_c(url2,"/reviews/")
  webpage2 <- read_html(url_review)
  review_data <- html_text(html_nodes(webpage2, ".overflow-text__content div" ))
  review=c(review,review_data)
  }
  review
  }
review <- get_review(get_names(4))
```



```{r, echo = FALSE}
# Initialize data frame of reviews, write a for loop to fill the first column by different school names. Save as df_review. 
schools <-get_real_names(4)
df_review <- data.frame(id=1:2000,text=review,stringsAsFactors=FALSE)
 
 for (i in 1:100){
 df_review$id[(20*(i-1)+1):(20*i)] <- schools[i]
}
```




```{r, echo = FALSE}
#seperate each review to single words, elimiate some non-sentimental words and rename the text column as word.
tidy_review <- df_review %>%
  unnest_tokens(word,text)%>%
  anti_join(stop_words)
#do the inner join with "bing" to create a new data frame that contains only words of sentiment.
review_sentiment <- tidy_review %>% 
    # Group by id
    group_by(id) %>% 
    # Define a new column review_total
    mutate(review_total = n()) %>%
    ungroup()%>%
    inner_join(get_sentiments("bing"))
# see how many world are positive and negative among all review
pos_neg <-review_sentiment%>%
    count(sentiment,sort=TRUE)
    
#group by by id and word, and count the appearance of different words for each university
top <- review_sentiment %>% group_by(id,word) %>%
   summarize(count=n()) %>%
  arrange(id,desc(count))
#get top 20 most appear words for each school.
top20 <- top_n(top,20)
top20
  
```



```{r, echo = FALSE}
#write a function to visualize the top 20 words for each school
colors<-brewer.pal(8,"Dark2")
colors_range<-colorRampPalette(colors)
wordcloud_top20 <- function(x){
wordcloud(words=filter(top20,id==x)$word,freq=top20$count,min.freq = 1,max.words=100000,random.order=TRUE,rot.per=0.5,col=colors_range(100))
}
```

Here we have the 20 most common sentimental words used to describe Brown University.

```{r, echo = F}
wordcloud_top20("Brown University")
```

Here we have the 20 most common sentimental words used to describe the Massachusetts Institute of Technology.

```{r, echo = F}
wordcloud_top20("Massachusetts Institute of Technology")
```

Here we have the 20 most common sentimental words used to describe Texas A&M University, which has the lowest sentiment ranking out of the top 100 schools.

```{r}
wordcloud_top20("Texas A&M University")
```

We can see that there is no relationship between schools' rank and the proportion of negative vs. positive reviews, which we will anaylyze later on. 

```{r, echo = FALSE}
#plot proportion of negative vs postive words for each school 
ggplot(review_sentiment,aes(x=id,fill=sentiment))+geom_bar(position="fill")+labs(x="School Ranking Highest to Lowest",y="Proportion") +
  scale_x_discrete(labels = c(rep("", 100)))
```


```{r, echo = FALSE}
#do the inner join with "afinn" to create a new data frame that contains only words of sentiment and their score.
review_score <- tidy_review %>% 
    # Group by id
    group_by(id) %>% 
    # Define a new column review_total
    mutate(review_total = n()) %>%
    ungroup()%>%
    inner_join(get_sentiments("afinn"))
# review_score
```

```{r, echo = FALSE}
#create a data frame which have the total score of sentiment test for each school
#create another data frame that have the old rank from niche.com
school_score <- review_score %>%
  group_by(id)%>%
  summarise(total_score=sum(score)) %>%
  arrange(desc(total_score))
# as.data.frame(school_score)
old_rank <- data.frame(id=schools,ori_rank=1:100)
# old_rank
```
We do the sentiment ananlysis by the sentiment tool "afinn", which gives each schools a total score(total_score) calculated by the words appeared on the reivew, and we create a data frame to show the new rank(rev_rank) of schools according to their review score. We also include the old rank(ori_rank) from niche.com and its difference(rank_diff) with new rank.
```{r, echo = F}
#compare new rank with old rank in a same data frame and displace their ranks' difference
compare_rank <- full_join(old_rank, school_score, by="id") %>%
  mutate(rev_rank=round(rank(desc(total_score)))) %>%
  mutate(rank_diff=ori_rank-rev_rank)
as.data.frame(compare_rank)
```

From the plot we can see that the old rank is not associated with the attitude of their review, becasue the p value of the linear regression have a p-value > 0.05, so we fail to reject the null hypothesis. In general, university students tend to put good reviews about their schools, so their reviews may not be very informative for perspective student.

```{r, echo = F}
#plot the old rank with the total score
ggplot(data=compare_rank,aes(x=ori_rank,y=total_score))+
  labs(title = "Sentiment Score vs Original Rank", x = "Original Rank", y = "Total Sentiment Score") +
  geom_point()
summary(lm(total_score~ori_rank,data=compare_rank))
```